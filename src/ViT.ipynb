{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cài vào đúng Python của kernel hiện tại\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install tensorboard\n",
    "\n",
    "# 2) Kiểm tra cài thành công\n",
    "import importlib, pkgutil\n",
    "spec = importlib.util.find_spec(\"tensorboard\")\n",
    "print(\"tensorboard found:\", spec is not None)\n",
    "if spec:\n",
    "    import tensorboard\n",
    "    print(\"tensorboard version:\", tensorboard.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import timm\n",
    "    _USE_TIMM = True\n",
    "except ImportError:\n",
    "    _USE_TIMM = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, root_dir='/Users/braly/Desktop/lmvh/plant-identify/dataset',\n",
    "                 split='train',\n",
    "                 transform=None,\n",
    "                 extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): đường dẫn tới thư mục chứa train/val/test\n",
    "            split (str): 'train' | 'val' | 'test'\n",
    "            transform (callable, optional): torchvision transforms or any callable applied lên PIL image\n",
    "            extensions (tuple): các hậu tố file ảnh chấp nhận\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.extensions = tuple(e.lower() for e in extensions)\n",
    "\n",
    "        self.images = []   # danh sách đường dẫn ảnh\n",
    "        self.labels = []   # label dưới dạng index\n",
    "        self.classes = []  # tên lớp (sorted)\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "\n",
    "        split_dir = os.path.join(self.root_dir, self.split)\n",
    "        if not os.path.isdir(split_dir):\n",
    "            raise ValueError(f\"Split folder not found: {split_dir}\")\n",
    "\n",
    "        # Lấy danh sách lớp (thư mục con) và map sang index\n",
    "        classes = [d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))]\n",
    "        classes = sorted(classes)\n",
    "        if len(classes) == 0:\n",
    "            raise ValueError(f\"No class subfolders found in {split_dir}\")\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "\n",
    "        # Duyệt từng thư mục lớp và thu thập ảnh\n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(split_dir, cls_name)\n",
    "            for root, _, files in os.walk(cls_dir):\n",
    "                for fname in files:\n",
    "                    if fname.lower().endswith(self.extensions):\n",
    "                        path = os.path.join(root, fname)\n",
    "                        self.images.append(path)\n",
    "                        self.labels.append(self.class_to_idx[cls_name])\n",
    "\n",
    "        if len(self.images) == 0:\n",
    "            raise ValueError(f\"No images found in {split_dir} with extensions {self.extensions}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Trả về: (image, label_index)\n",
    "        - image: PIL.Image (nếu transform None) hoặc transform(image)\n",
    "        - label_index: int (index của lớp)\n",
    "        \"\"\"\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Mở ảnh an toàn\n",
    "        with open(img_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    # Tiện ích: trả về số ảnh / lớp\n",
    "    def get_class_counts(self):\n",
    "        \"\"\"Trả về dict: {class_name: count}\"\"\"\n",
    "        counts = Counter()\n",
    "        for lbl in self.labels:\n",
    "            counts[self.idx_to_class[lbl]] += 1\n",
    "        return dict(counts)\n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"In thông tin tóm tắt dataset\"\"\"\n",
    "        total = len(self)\n",
    "        counts = self.get_class_counts()\n",
    "        print(f\"Dataset split: {self.split}\")\n",
    "        print(f\"Root dir: {self.root_dir}\")\n",
    "        print(f\"Total images: {total}\")\n",
    "        print(\"Number of classes:\", len(self.classes))\n",
    "        print(\"Class -> index mapping:\")\n",
    "        for cls, idx in self.class_to_idx.items():\n",
    "            print(f\"  {cls:20s} -> {idx:3d} ({counts.get(cls,0)} images)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root = '/Users/braly/Desktop/lmvh/plant-identify/dataset'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = PlantDataset(root_dir=root, split='train', transform=transform)\n",
    "val_ds   = PlantDataset(root_dir=root, split='valid', transform=transform)\n",
    "test_ds  = PlantDataset(root_dir=root, split='test', transform=transform)\n",
    "\n",
    "train_ds.print_stats()\n",
    "print(\"Total train images:\", len(train_ds))\n",
    "\n",
    "# Lấy 1 mẫu\n",
    "img, label = train_ds[0]\n",
    "print(type(img), label)  # img là Tensor nếu transform -> ToTensor, label là int (index)\n",
    "\n",
    "# Dùng DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 root_dir: str,\n",
    "                 image_size: int = 224,\n",
    "                 batch_size: int = 32,\n",
    "                 num_workers: int = 4,\n",
    "                 pin_memory: bool = True):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "\n",
    "        # transforms\n",
    "        self.train_transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomRotation(10),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        self.val_transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        # placeholders set in setup()\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        # Called on every GPU in DDP — keep idempotent\n",
    "        if stage in (None, 'fit'):\n",
    "            self.train_dataset = PlantDataset(self.root_dir, split='train', transform=self.train_transform)\n",
    "            self.val_dataset = PlantDataset(self.root_dir, split='valid', transform=self.val_transform)\n",
    "            self.num_classes = len(self.train_dataset.classes)\n",
    "        if stage in (None, 'test'):\n",
    "            self.test_dataset = PlantDataset(self.root_dir, split='test', transform=self.val_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=self.num_workers,\n",
    "                          pin_memory=self.pin_memory)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=self.num_workers,\n",
    "                          pin_memory=self.pin_memory)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.test_dataset is None:\n",
    "            return None\n",
    "        return DataLoader(self.test_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=self.num_workers,\n",
    "                          pin_memory=self.pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTLightning(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 lr: float = 3e-4,\n",
    "                 weight_decay: float = 1e-2,\n",
    "                 backbone_name: str = \"vit_base_patch16_224\",\n",
    "                 pretrained: bool = True,\n",
    "                 freeze_backbone: bool = False):\n",
    "        \"\"\"\n",
    "        If timm is available, use timm.create_model(backbone_name, pretrained=True, num_classes=num_classes).\n",
    "        Otherwise try torchvision's vit_b_16 (if installed).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.backbone_name = backbone_name\n",
    "        self.pretrained = pretrained\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "\n",
    "        # Build model\n",
    "        if _USE_TIMM:\n",
    "            # timm handles classifier creation\n",
    "            self.model = timm.create_model(self.backbone_name, pretrained=self.pretrained, num_classes=self.num_classes)\n",
    "        else:\n",
    "            # fallback to torchvision ViT if available\n",
    "            try:\n",
    "                from torchvision import models as tv_models\n",
    "                vit_builder = getattr(tv_models, \"vit_b_16\", None)\n",
    "                if vit_builder is None:\n",
    "                    raise RuntimeError(\"torchvision ViT not available; please install timm.\")\n",
    "                # torchvision vit builder signatures vary; try to create without classifier then add head\n",
    "                backbone = vit_builder(weights=\"IMAGENET1K_V1\") if hasattr(vit_builder, '__call__') else vit_builder(pretrained=self.pretrained)\n",
    "                # remove existing head if present\n",
    "                if hasattr(backbone, 'heads'):\n",
    "                    feat_dim = backbone.heads.head.in_features if hasattr(backbone.heads, 'head') else getattr(backbone, 'hidden_dim', 768)\n",
    "                    backbone.heads = nn.Identity()\n",
    "                elif hasattr(backbone, 'head'):\n",
    "                    feat_dim = backbone.head.in_features\n",
    "                    backbone.head = nn.Identity()\n",
    "                else:\n",
    "                    feat_dim = getattr(backbone, 'hidden_dim', 768)\n",
    "                # create classifier\n",
    "                head = nn.Linear(feat_dim, self.num_classes)\n",
    "                self.model = nn.Sequential(backbone, head)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\"No ViT backbone available. Install timm or use recent torchvision.\") from e\n",
    "\n",
    "        # optionally freeze backbone parameters for fine-tuning head only\n",
    "        if self.freeze_backbone:\n",
    "            for name, p in self.model.named_parameters():\n",
    "                if \"head\" not in name and \"heads\" not in name and \"classifier\" not in name:\n",
    "                    p.requires_grad = False\n",
    "\n",
    "        # loss + metrics\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # use torchmetrics for metrics if available\n",
    "        try:\n",
    "            import torchmetrics\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        except Exception:\n",
    "            # fallback simple trackers\n",
    "            self.train_acc = None\n",
    "            self.val_acc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # log loss\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, prog_bar=False)\n",
    "        if self.train_acc is not None:\n",
    "            acc = self.train_acc(preds, y)\n",
    "            self.log(\"train/acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        else:\n",
    "            # rough acc\n",
    "            acc = (preds == y).float().mean()\n",
    "            self.log(\"train/acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        if self.val_acc is not None:\n",
    "            acc = self.val_acc(preds, y)\n",
    "            self.log(\"val/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        else:\n",
    "            acc = (preds == y).float().mean()\n",
    "            self.log(\"val/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "        if self.val_acc is not None:\n",
    "            acc = self.val_acc(preds, y)\n",
    "            self.log(\"test/acc\", acc, on_step=False, on_epoch=True)\n",
    "        else:\n",
    "            acc = (preds == y).float().mean()\n",
    "            self.log(\"test/acc\", acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # small scheduler example (cosine)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val/loss\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Callback lưu loss/acc mỗi epoch để sau đó vẽ\n",
    "class LossHistory(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "\n",
    "    def _get_metric(self, trainer, keys):\n",
    "        \"\"\"Trả về float hoặc None — keys là list các key thử (khác PL versions có key khác nhau).\"\"\"\n",
    "        for k in keys:\n",
    "            if k in trainer.callback_metrics:\n",
    "                v = trainer.callback_metrics[k]\n",
    "                try:\n",
    "                    return float(v)\n",
    "                except Exception:\n",
    "                    return float(v.item())\n",
    "        return None\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Thường trainer.callback_metrics sẽ chứa \"train/loss\" (on_epoch=True) và \"val/loss\"\n",
    "        tr_loss = self._get_metric(trainer, [\"train/loss\", \"train_loss\", \"train/loss_epoch\", \"train_loss_epoch\"])\n",
    "        v_loss = self._get_metric(trainer, [\"val/loss\", \"val_loss\", \"val/loss_epoch\", \"val_loss_epoch\"])\n",
    "        v_acc  = self._get_metric(trainer, [\"val/acc\", \"val_acc\", \"val/acc_epoch\", \"val_acc_epoch\"])\n",
    "\n",
    "        # Append only when available (safety)\n",
    "        if tr_loss is not None:\n",
    "            self.train_losses.append(tr_loss)\n",
    "        if v_loss is not None:\n",
    "            self.val_losses.append(v_loss)\n",
    "        if v_acc is not None:\n",
    "            self.val_accs.append(v_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay đường dẫn dataset của bạn ở đây\n",
    "data_dir = \"/Users/braly/Desktop/lmvh/plant-identify/dataset\"\n",
    "\n",
    "# hyperparams\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "max_epochs = 10   # chỉnh tuỳ ý\n",
    "precision = 16 if torch.cuda.is_available() else 32\n",
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Nếu bạn đã có PlantDataModule và ViTLightning trong notebook, dùng trực tiếp:\n",
    "dm = PlantDataModule(root_dir=data_dir,\n",
    "                     image_size=image_size,\n",
    "                     batch_size=batch_size,\n",
    "                     num_workers=num_workers)\n",
    "dm.setup('fit')\n",
    "print(\"Num classes:\", dm.num_classes)\n",
    "\n",
    "model = ViTLightning(num_classes=dm.num_classes,\n",
    "                     lr=3e-4,\n",
    "                     weight_decay=1e-2,\n",
    "                     backbone_name=\"vit_base_patch16_224\",\n",
    "                     pretrained=True,\n",
    "                     freeze_backbone=False)\n",
    "\n",
    "# Logger + callbacks\n",
    "logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"vit_plants_notebook\")\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    monitor=\"val/acc\",     # nếu bạn muốn monitor val/loss thay \"val/acc\"\n",
    "    mode=\"max\",\n",
    "    save_top_k=3,\n",
    "    filename=\"vit-{epoch:02d}-{val/acc:.4f}\"\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "loss_hist_cb = LossHistory()\n",
    "devices_for_trainer = gpus if gpus > 0 else 1\n",
    "# Trainer (an toàn trong notebook: devices=None nếu no GPU)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"gpu\" if gpus > 0 else \"cpu\",\n",
    "    devices=gpus if gpus > 0 else 1,  # <-- sửa None thành 1\n",
    "    precision=precision,\n",
    "    callbacks=[checkpoint_cb, lr_monitor, loss_hist_cb],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    "    enable_progress_bar=True,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu checkpoint (trainer đã tự lưu theo callback ModelCheckpoint).\n",
    "print(\"Best checkpoint path:\", checkpoint_cb.best_model_path)\n",
    "\n",
    "# Lưu state_dict final của LightningModule (dùng để load bằng model.load_state_dict)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "final_path = \"saved_models/vit_plants_final_state_dict.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(\"Saved state_dict to:\", final_path)\n",
    "\n",
    "# Nếu muốn lưu toàn bộ checkpoint (bao gồm optimizer state) dùng:\n",
    "trainer.save_checkpoint(\"saved_models/vit_plants_full_checkpoint.ckpt\")\n",
    "print(\"Saved full checkpoint to saved_models/vit_plants_full_checkpoint.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# --- Cấu hình đường dẫn ---\n",
    "ckpt_path = \"/Users/braly/Desktop/lmvh/plant-identify/saved_models/vit_plants_full_checkpoint.ckpt\"  # hoặc .ckpt file bạn có\n",
    "image_path = \"/Users/braly/Desktop/lmvh/plant-identify/dataset/train/Christmas Cactus (Schlumbergera bridgesii)/images (8).jpeg\"  # ảnh muốn test\n",
    "root_dir = root # nếu muốn load classes từ dataset\n",
    "\n",
    "# --- Device (hỗ trợ cuda / mps / cpu) ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# --- Transforms (giữ như val_transform trong DataModule) ---\n",
    "image_size = 224\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((image_size, image_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# --- Load tên lớp (nếu bạn dùng PlantDataset như khi train) ---\n",
    "try:\n",
    "    # Nếu bạn đã định nghĩa PlantDataset trong cùng file, dùng để lấy tên lớp\n",
    "    dataset_for_classes = PlantDataset(root_dir=root_dir, split='train')\n",
    "    classes = dataset_for_classes.classes\n",
    "    print(f\"Loaded {len(classes)} classes from dataset.\")\n",
    "except Exception as e:\n",
    "    # fallback: nếu không thể load dataset, bạn có thể cung cấp thủ công:\n",
    "    print(\"Không load được dataset để lấy classes:\", e)\n",
    "    # Ví dụ: classes = [\"classA\", \"classB\", ...]\n",
    "    classes = None\n",
    "\n",
    "# --- Load model từ checkpoint ---\n",
    "model = None\n",
    "try:\n",
    "    # Thử load trực tiếp (Lightning lưu hparams vào checkpoint nên thường OK)\n",
    "    model = ViTLightning.load_from_checkpoint(ckpt_path, map_location=device)\n",
    "    print(\"Loaded model via ViTLightning.load_from_checkpoint()\")\n",
    "except Exception as e:\n",
    "    print(\"load_from_checkpoint failed:\", e)\n",
    "    # Nếu thất bại, thử load state_dict và khởi tạo model thủ công.\n",
    "    # Bạn có thể cần truyền num_classes nếu required.\n",
    "    # Cố gắng lấy num_classes từ dataset nếu có\n",
    "    if classes is not None:\n",
    "        num_classes = len(classes)\n",
    "    else:\n",
    "        # nếu không có classes, hãy đặt đúng số lớp bạn đã train\n",
    "        num_classes = 47  # <--- sửa theo số lớp thật nếu cần\n",
    "\n",
    "    # Khởi tạo model (tham số phải phù hợp với lúc train)\n",
    "    model = ViTLightning(num_classes=num_classes,\n",
    "                         lr=3e-4,\n",
    "                         weight_decay=1e-2,\n",
    "                         backbone_name=\"vit_base_patch16_224\",\n",
    "                         pretrained=False,\n",
    "                         freeze_backbone=False)\n",
    "    # Load checkpoint file\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    if \"state_dict\" in ckpt:\n",
    "        state_dict = ckpt[\"state_dict\"]\n",
    "    else:\n",
    "        state_dict = ckpt  # có thể trực tiếp là state_dict\n",
    "    # Một số key khi lưu bởi Lightning có tiền tố \"model.\" hoặc \"net.\"\n",
    "    # Nếu keys mismatch, cố gắng strip tiền tố common (ví dụ \"model.\")\n",
    "    new_state = {}\n",
    "    for k, v in state_dict.items():\n",
    "        new_k = k\n",
    "        if k.startswith(\"model.\"):\n",
    "            new_k = k[len(\"model.\"):]\n",
    "        new_state[new_k] = v\n",
    "    model.load_state_dict(new_state, strict=False)\n",
    "    print(\"Loaded state_dict into newly created model.\")\n",
    "\n",
    "# --- Chuẩn bị model để inference ---\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# --- Load và tiền xử lý ảnh ---\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "x = val_transform(img).unsqueeze(0).to(device)  # shape (1,C,H,W)\n",
    "\n",
    "# --- Inference ---\n",
    "with torch.no_grad():\n",
    "    logits = model(x)  # (1, num_classes) — tùy backbone output trực tiếp logits\n",
    "    if isinstance(logits, tuple) or isinstance(logits, list):\n",
    "        logits = logits[0]\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    topk = torch.topk(probs, k=min(5, probs.shape[1]), dim=1)\n",
    "\n",
    "top_probs = topk.values.cpu().numpy()[0]\n",
    "top_idxs = topk.indices.cpu().numpy()[0]\n",
    "\n",
    "# --- Hiển thị kết quả ---\n",
    "if classes is None:\n",
    "    # Nếu không có tên lớp, in idx\n",
    "    for i, (idx, p) in enumerate(zip(top_idxs, top_probs), 1):\n",
    "        print(f\"#{i}: class_idx={idx}  prob={p:.4f}\")\n",
    "else:\n",
    "    for i, (idx, p) in enumerate(zip(top_idxs, top_probs), 1):\n",
    "        class_name = classes[int(idx)]\n",
    "        print(f\"#{i}: {class_name} (idx={idx})  prob={p:.4f}\")\n",
    "\n",
    "# (Tùy ý) Hiển thị ảnh trong notebook (nếu dùng notebook)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"Input image:\")\n",
    "    display(img)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
